{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb08512",
   "metadata": {},
   "source": [
    "# INF581 - Lab 02\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In Lab 01, we looked at a full pipeline for an agent, from perception to inference (reasoning from knowledge $P$) and decision making. However, there were two elements worth studying:\n",
    "\n",
    "1. Scalability -- how to perform approximate inference when it is not feasible to track all feasible solutions?\n",
    "2. Learning -- if $P$ is not available beforehand; how to assimilate knowledge from data (machine learning, and deep learning)?\n",
    "\n",
    "We approach these questions through the lens of multi-label learning, but the answers could be equally applied as an extension to Lab 01.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dfadd5",
   "metadata": {},
   "source": [
    "## Task 0: Enter your ID\n",
    "\n",
    "Don't forget to enter your email address in the box below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636e7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT ID\n",
    "\n",
    "# TODO replace the following Email with your own\n",
    "    \n",
    "info = {\n",
    "        'Email' : 'yannis.kedadry@polytechnique.edu',\n",
    "        'Alias' : 'yKedadry', # (change this in case you want to identify yourself on the leaderboard)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad04b83",
   "metadata": {},
   "source": [
    "## Part 1: Scalability (Monte Carlo Search)\n",
    "\n",
    "In classifier chains (see lecture slides for background and illustration), we have a Bayesian network which specifies a joint distribution over outputs $p(y_1,\\ldots,y_m)$. Due to the high connectivity in the DAG, there are $2^m$ possible combinations of outputs. \n",
    "\n",
    "One option is to do _greedy_ inference, this is certainly scalable; but greedy is not the same as _optimal_, and we would like an approximation that is closer to optimal. You will implement Monte Carlo search for inference.\n",
    "\n",
    "But first, \n",
    "\n",
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e3fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT Imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41eccfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def draw_tree(nodes,edges,y_pred=None,p_pred=None,title=''):\n",
    "    '''\n",
    "        draw a tree, with these nodes and edges\n",
    "    '''\n",
    "    G = Digraph(comment=title)\n",
    "    G.node_attr.update(shape='box', style='rounded')\n",
    "    for n in nodes.keys():\n",
    "        if n == str(y_pred) and nodes[n] == p_pred:\n",
    "            G.node(n,label='''<{<B>%s</B> | %3.2f}>''' % (n,nodes[n]),shape='record',fontcolor='blue')\n",
    "        else:\n",
    "            G.node(n,label='''<{<B>%s</B> | %3.2f}>''' % (n,nodes[n]),shape='record')\n",
    "    for e_key in edges.keys():\n",
    "        l,r = e_key.split('--')\n",
    "        G.edge(l,r,\"%3.2f\" % edges[e_key])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8119d0d",
   "metadata": {},
   "source": [
    "### Training Classifier Chains\n",
    "\n",
    "The following code simply trains classifier chains on the music-emotions dataset (Trohidis et al., 2011), where attributes describing a piece of music are associated to a subset of six emotions: amazed-surprised, happy-pleased, relaxing-clam, quiet-still, sad-lonely, and angry-aggressive. \n",
    "\n",
    "We use a random node ordering in the chain. But, of course, it is a legitimate question (outside the scope of this lab task): which is the best order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b9e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "m = 6\n",
    "XY = np.genfromtxt('music.csv', skip_header=1, delimiter=\",\")\n",
    "n,d_plus_m = XY.shape\n",
    "d = d_plus_m - m\n",
    "X = XY[:,m:d_plus_m]\n",
    "Y = XY[:,0:m]\n",
    "n_test = 1\n",
    "n_train = n-n_test\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size=n_test, random_state=random_state)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "cc = ClassifierChain(LogisticRegression(solver='liblinear'), order=\"random\", random_state=random_state)\n",
    "cc.fit(X_train,Y_train)\n",
    "\n",
    "# Instantiate all models of the chain\n",
    "chain = [LogisticRegression(solver='liblinear') for j in range(m)]\n",
    "\n",
    "# Prepare the feature and target space(s)\n",
    "XY = np.zeros((n, d + m-1))\n",
    "XY[:,0:d] = X\n",
    "XY[:,d:] = Y[:,0:m-1]\n",
    "\n",
    "# Train each individual classifier\n",
    "for j in range(m):\n",
    "    chain[j].fit(XY[:,0:d+j], Y[:,j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f894f",
   "metadata": {},
   "source": [
    "### Greedy inference\n",
    "\n",
    "In the following there is an example of greedy inference. Essentially, this is $\\mathbf{\\hat y} = h(\\mathbf{x})$ where $\\mathbf{x}$ is the test instance and Bayesian network $p$ is provided via the probabilistic classifiers in `chain`. The function returns both $\\mathbf{y}$ and its associated probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1ac838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(x, h, nodes = {}, edges = {}):\n",
    "    \"\"\" Inference via greedy search.\n",
    "    \n",
    "        Determines argmax_y p(y|x). \n",
    "        \n",
    "        (And also fills `nodes` and `edges` for visualization later)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        x : array_like (float, ndim=1) of length n_features \n",
    "            test instance\n",
    "\n",
    "        h : list (of classifiers)\n",
    "            the probabilistic classifiers that represent the chain\n",
    "\n",
    "        nodes : dict(str,float)\n",
    "            where dict[str(y)] = P(y | x)\n",
    "\n",
    "        edges : dict(str,float)\n",
    "            where dict[str(y)+'--'+str(y)] = P(y[j] | y[j-1], x) \n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        y : array_like(int,ndim=1) array of length m\n",
    "            label vector\n",
    "\n",
    "        p : float\n",
    "            P(y | x) the posterior probability \n",
    "    \"\"\"\n",
    "\n",
    "    m = len(h)\n",
    "    y = np.zeros(m, dtype=int)              # an array to store labels (best path)\n",
    "    p = 1.                       # path score 'so far'\n",
    "    xy = x.reshape(1,-1)         # array of shape (n_labels,n_features) is required by sklearn\n",
    "\n",
    "    for j in range(m):\n",
    "        if j>0:\n",
    "            # stack the previous y as an additional feature\n",
    "            xy = np.column_stack([xy, y[j-1]])\n",
    "        # P_j := P(y[j]|x,y[1],...,y[j-1])\n",
    "        P_j = h[j].predict_proba(xy)[0] # (N.B. [0], because it is the first and only row)\n",
    "        k = np.argmax(P_j)\n",
    "        y[j] = k\n",
    "        p = p * P_j[k]\n",
    "\n",
    "        edges[str(y[0:j])+'--'+str(y[0:j+1])] = P_j[k]\n",
    "        nodes[str(y[0:j+1])] = p\n",
    "\n",
    "    return y,p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f829b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"92pt\" height=\"659pt\"\n",
       " viewBox=\"0.00 0.00 92.25 659.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 655)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-655 88.25,-655 88.25,4 -4,4\"/>\n",
       "<!-- [0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>[0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27.12,-513C27.12,-513 57.12,-513 57.12,-513 63.12,-513 69.12,-519 69.12,-525 69.12,-525 69.12,-550 69.12,-550 69.12,-556 63.12,-562 57.12,-562 57.12,-562 27.12,-562 27.12,-562 21.12,-562 15.12,-556 15.12,-550 15.12,-550 15.12,-525 15.12,-525 15.12,-519 21.12,-513 27.12,-513\"/>\n",
       "<text text-anchor=\"start\" x=\"34.25\" y=\"-545.7\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">[0]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"15.12,-537.5 69.12,-537.5\"/>\n",
       "<text text-anchor=\"start\" x=\"30.12\" y=\"-520.2\" font-family=\"Times,serif\" font-size=\"14.00\">0.90</text>\n",
       "</g>\n",
       "<!-- [0 0] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>[0 0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27.12,-410.5C27.12,-410.5 57.12,-410.5 57.12,-410.5 63.12,-410.5 69.12,-416.5 69.12,-422.5 69.12,-422.5 69.12,-447.5 69.12,-447.5 69.12,-453.5 63.12,-459.5 57.12,-459.5 57.12,-459.5 27.12,-459.5 27.12,-459.5 21.12,-459.5 15.12,-453.5 15.12,-447.5 15.12,-447.5 15.12,-422.5 15.12,-422.5 15.12,-416.5 21.12,-410.5 27.12,-410.5\"/>\n",
       "<text text-anchor=\"start\" x=\"28.62\" y=\"-443.2\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">[0 0]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"15.12,-435 68.38,-435\"/>\n",
       "<text text-anchor=\"start\" x=\"29.75\" y=\"-417.7\" font-family=\"Times,serif\" font-size=\"14.00\">0.55</text>\n",
       "</g>\n",
       "<!-- [0]&#45;&gt;[0 0] -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>[0]&#45;&gt;[0 0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.12,-512.68C42.12,-500.38 42.12,-485.13 42.12,-471.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.63,-471.51 42.13,-461.51 38.63,-471.51 45.63,-471.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-481.2\" font-family=\"Times,serif\" font-size=\"14.00\">0.61</text>\n",
       "</g>\n",
       "<!-- [0 0 1] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>[0 0 1]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27.12,-308C27.12,-308 57.12,-308 57.12,-308 63.12,-308 69.12,-314 69.12,-320 69.12,-320 69.12,-345 69.12,-345 69.12,-351 63.12,-357 57.12,-357 57.12,-357 27.12,-357 27.12,-357 21.12,-357 15.12,-351 15.12,-345 15.12,-345 15.12,-320 15.12,-320 15.12,-314 21.12,-308 27.12,-308\"/>\n",
       "<text text-anchor=\"start\" x=\"23.62\" y=\"-340.7\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">[0 0 1]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"15.12,-332.5 68.88,-332.5\"/>\n",
       "<text text-anchor=\"start\" x=\"30\" y=\"-315.2\" font-family=\"Times,serif\" font-size=\"14.00\">0.29</text>\n",
       "</g>\n",
       "<!-- [0 0]&#45;&gt;[0 0 1] -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>[0 0]&#45;&gt;[0 0 1]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.12,-410.18C42.12,-397.88 42.12,-382.63 42.12,-368.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.63,-369.01 42.13,-359.01 38.63,-369.01 45.63,-369.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-378.7\" font-family=\"Times,serif\" font-size=\"14.00\">0.52</text>\n",
       "</g>\n",
       "<!-- [0 0 1 0] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>[0 0 1 0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M22.5,-205.5C22.5,-205.5 61.75,-205.5 61.75,-205.5 67.75,-205.5 73.75,-211.5 73.75,-217.5 73.75,-217.5 73.75,-242.5 73.75,-242.5 73.75,-248.5 67.75,-254.5 61.75,-254.5 61.75,-254.5 22.5,-254.5 22.5,-254.5 16.5,-254.5 10.5,-248.5 10.5,-242.5 10.5,-242.5 10.5,-217.5 10.5,-217.5 10.5,-211.5 16.5,-205.5 22.5,-205.5\"/>\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-238.2\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">[0 0 1 0]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"10.5,-230 73.75,-230\"/>\n",
       "<text text-anchor=\"start\" x=\"30.12\" y=\"-212.7\" font-family=\"Times,serif\" font-size=\"14.00\">0.24</text>\n",
       "</g>\n",
       "<!-- [0 0 1]&#45;&gt;[0 0 1 0] -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>[0 0 1]&#45;&gt;[0 0 1 0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.12,-307.68C42.12,-295.38 42.12,-280.13 42.12,-266.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.63,-266.51 42.13,-256.51 38.63,-266.51 45.63,-266.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-276.2\" font-family=\"Times,serif\" font-size=\"14.00\">0.84</text>\n",
       "</g>\n",
       "<!-- [0 0 1 0 1] -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>[0 0 1 0 1]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M17.25,-103C17.25,-103 67,-103 67,-103 73,-103 79,-109 79,-115 79,-115 79,-140 79,-140 79,-146 73,-152 67,-152 67,-152 17.25,-152 17.25,-152 11.25,-152 5.25,-146 5.25,-140 5.25,-140 5.25,-115 5.25,-115 5.25,-109 11.25,-103 17.25,-103\"/>\n",
       "<text text-anchor=\"start\" x=\"13.25\" y=\"-135.7\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">[0 0 1 0 1]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5.25,-127.5 79,-127.5\"/>\n",
       "<text text-anchor=\"start\" x=\"30.12\" y=\"-110.2\" font-family=\"Times,serif\" font-size=\"14.00\">0.14</text>\n",
       "</g>\n",
       "<!-- [0 0 1 0]&#45;&gt;[0 0 1 0 1] -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>[0 0 1 0]&#45;&gt;[0 0 1 0 1]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.12,-205.18C42.12,-192.88 42.12,-177.63 42.12,-163.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.63,-164.01 42.13,-154.01 38.63,-164.01 45.63,-164.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-173.7\" font-family=\"Times,serif\" font-size=\"14.00\">0.59</text>\n",
       "</g>\n",
       "<!-- [0 0 1 0 1 0] -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>[0 0 1 0 1 0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12,-0.5C12,-0.5 72.25,-0.5 72.25,-0.5 78.25,-0.5 84.25,-6.5 84.25,-12.5 84.25,-12.5 84.25,-37.5 84.25,-37.5 84.25,-43.5 78.25,-49.5 72.25,-49.5 72.25,-49.5 12,-49.5 12,-49.5 6,-49.5 0,-43.5 0,-37.5 0,-37.5 0,-12.5 0,-12.5 0,-6.5 6,-0.5 12,-0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-33.2\" font-family=\"Times,serif\" font-weight=\"bold\" font-size=\"14.00\">[0 0 1 0 1 0]</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-25 84.25,-25\"/>\n",
       "<text text-anchor=\"start\" x=\"30.12\" y=\"-7.7\" font-family=\"Times,serif\" font-size=\"14.00\">0.14</text>\n",
       "</g>\n",
       "<!-- [0 0 1 0 1]&#45;&gt;[0 0 1 0 1 0] -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>[0 0 1 0 1]&#45;&gt;[0 0 1 0 1 0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.12,-102.68C42.12,-90.38 42.12,-75.13 42.12,-61.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.63,-61.51 42.13,-51.51 38.63,-61.51 45.63,-61.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-71.2\" font-family=\"Times,serif\" font-size=\"14.00\">0.99</text>\n",
       "</g>\n",
       "<!-- [] -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>[]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.12,-651C57.12,-651 27.12,-651 27.12,-651 21.12,-651 15.12,-645 15.12,-639 15.12,-639 15.12,-627 15.12,-627 15.12,-621 21.12,-615 27.12,-615 27.12,-615 57.12,-615 57.12,-615 63.12,-615 69.12,-621 69.12,-627 69.12,-627 69.12,-639 69.12,-639 69.12,-645 63.12,-651 57.12,-651\"/>\n",
       "<text text-anchor=\"middle\" x=\"42.12\" y=\"-627.95\" font-family=\"Times,serif\" font-size=\"14.00\">[]</text>\n",
       "</g>\n",
       "<!-- []&#45;&gt;[0] -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>[]&#45;&gt;[0]</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.12,-614.85C42.12,-603.32 42.12,-587.7 42.12,-573.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.63,-573.74 42.13,-563.74 38.63,-573.74 45.63,-573.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"54.12\" y=\"-583.7\" font-family=\"Times,serif\" font-size=\"14.00\">0.90</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7ff4a6d5b3d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw the resulting 'tree'\n",
    "nodes = {}\n",
    "edges = {}\n",
    "y_greedy, p_greedy = greedy(x_test, chain, nodes, edges)\n",
    "G = draw_tree(nodes,edges)\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff647e4",
   "metadata": {},
   "source": [
    "### Task 1: Implementing Monte Carlo Search\n",
    "\n",
    "The function `sample` below should return a sample $\\mathbf{y} \\sim p(\\mathbf{y} | \\mathbf{x})$ where $\\mathbf{x}$ is the test instance and Bayesian network $p$ is provided via the probabilistic classifiers (logistic regression) in `chain`. Note that the function returns both $\\mathbf{y}$ and its associated probability. \n",
    "\n",
    "#### Task 1a: Implement the sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8be805",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT Task 1a\n",
    "\n",
    "def sample(x, h, nodes={}, edges={}):\n",
    "    '''\n",
    "        Sample y ~ P(y|x)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y: a sampled label vector\n",
    "        p: the associated probabilities, i.e., p(y_j=1)=p_j\n",
    "    '''\n",
    "    d = len(x)\n",
    "    m = len(h)\n",
    "\n",
    "    y = np.zeros(m,dtype=int)\n",
    "    p = 1.\n",
    "    \n",
    "    # TODO \n",
    "    \n",
    "    return y, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708195a",
   "metadata": {},
   "source": [
    "#### Task 1b Implement the inference function\n",
    "\n",
    "Complete the following function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d725a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT Task 1b\n",
    "\n",
    "def mc_search(x, h, nodes={}, edges={}, n_samples=10):\n",
    "    ''' mc search'''\n",
    "    p_max = 0\n",
    "    y_max = None\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    return y_max, p_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae45e9",
   "metadata": {},
   "source": [
    "Let's check how this compares to the 'greedy' prediction, for the same instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate \n",
    "nodes = {}\n",
    "edges = {}\n",
    "y_pred, p_pred = mc_search(x_test[0], chain, nodes, edges)\n",
    "# And compare vs greedy inference\n",
    "print(\"MC-Search: p(%s | x) = %3.2f\" % (str(y_pred), p_pred))\n",
    "print(\"   Greedy: p(%s | x) = %3.2f\" % (str(y_greedy), p_greedy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3844e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the resulting search tree\n",
    "G = draw_tree(nodes, edges, y_pred, p_pred)\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5224ac2",
   "metadata": {},
   "source": [
    "### Conclusions?\n",
    "\n",
    "Think about if/how Monte Carlo search could have been implemented for the tasks in Lab 01.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667ff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "625461d8",
   "metadata": {},
   "source": [
    "## Task 2: Machine Learning (PyTorch)\n",
    "\n",
    "In this task we will construct a deep architecture with two connected heads. Such architectures with multiple heads are commonplace in reinforcement learning (and other areas where non-simplistic architectures are required). It can even help in this case of multi-label learning (as opposed to a basic pipeline of layers from input to output).\n",
    "\n",
    "We will use the music-emotions data, as considered in Task 1, to keep the computational complexity reasonable. Hence, again, our interest is in: \n",
    "$$\n",
    "    p(\\mathbf{y} | \\mathbf{x})\n",
    "$$\n",
    "where $\\mathbf{y} = [y_1,\\ldots,y_m]$. \n",
    "\n",
    "The main objective of this task is firstly, appreciating the role that machine learning plays in providing a representation of knowledge, and secondly, becoming familiar with designing non-trivial architectures.\n",
    "\n",
    "This task assumes familiarity with PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15437fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-split the data (to have more test examples)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=100, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3566686b",
   "metadata": {},
   "source": [
    "### The Model  / Network\n",
    "\n",
    "You should design a network like this:\n",
    "* the first layer connects input `x` to hidden nodes `z` (ReLU activation)\n",
    "* another layer connects `z` to the first half of the outputs `l` (sigmoid activation), i.e., representing $y_1,y_2,y_3$. \n",
    "* we connect `l` to another layer `u`\n",
    "* finaly, connect *both* `z` and `u` to `r` which represents the second half of outputs (sigmoid activation), i.e., representing $y_4,y_5,y_6$.\n",
    "\n",
    "The sizes of `z` and `u` can be given in the parameter dictionary `sizes`.\n",
    "\n",
    "What justification for such an architecture? This is somewhere inbetween  classifier chains and more typical multi-output neural networks. We get a bit of 'capacity for free', but we also add the typical deep layer(s) of a neural network to properly embed the input and label concepts. If this hierarchical representation reflects the data, then we can (using, e.g., MC-search) estimate the joint probability $p(\\mathbf{y} | \\mathbf{x})$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT Task 2 \n",
    "\n",
    "class MyNetwork1(nn.Module):\n",
    "\n",
    "    def __init__(self, d, m, sizes = {'z' : 50, 'u' : 10}):\n",
    "        '''\n",
    "            Setup a network Module.\n",
    "\n",
    "            (as described above)\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "\n",
    "            d : int\n",
    "                number of input nodes/features\n",
    "            m : int\n",
    "                number of output nodes/labels/targets\n",
    "            sizes : dict.\n",
    "              specify the sizes of the 'hidden' layers\n",
    "\n",
    "        '''\n",
    "        super(MyNetwork1, self).__init__()\n",
    "\n",
    "        # TODO \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Defines the forward pass of the network, from input to output.\n",
    "\n",
    "            (again, you may use the description above)\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "\n",
    "            x : Tensor\n",
    "                representing the input instance(s)\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "\n",
    "            y : Tensor\n",
    "                representing the output labels\n",
    "        '''\n",
    "        # TODO \n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb060040",
   "metadata": {},
   "source": [
    "Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4214e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_deep = MyNetwork1(d,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98963a",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "How to train this thing? First question: under which loss? This is an important question. For now, let's use 'binary cross entropy'.\n",
    "\n",
    "Just run the following code to train your network (once you have implemented it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6fbc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT fit function\n",
    "\n",
    "def fit(h, X, Y, n_epochs=100):\n",
    "    '''\n",
    "        Train the network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : ptorch module\n",
    "            the network\n",
    "        X : numpy array of shape (n, d)\n",
    "            instances\n",
    "        Y : numpy array of shape (n, m)\n",
    "            labels\n",
    "        n_epochs : int\n",
    "            number of epochs\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Check the shape\n",
    "    n = len(X)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(h.parameters(),0.001)\n",
    "\n",
    "    # Loss\n",
    "    my_loss = torch.nn.BCELoss()\n",
    "\n",
    "    # Fit the Model\n",
    "    for t in range(n_epochs):\n",
    "        losses = []\n",
    "        for i in range(n):\n",
    "            h.train()\n",
    "\n",
    "            x_variable = torch.FloatTensor(X[i]).view(1, -1)\n",
    "            y_variable = torch.FloatTensor(Y[i]).view(1, -1)\n",
    "\n",
    "            output = h(x_variable)\n",
    "\n",
    "            loss = my_loss(output, y_variable)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.data.mean())\n",
    "        print('[%d/%d] Loss: %.3f' % (t+1, n_epochs, np.mean(losses)))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38612762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train it\n",
    "fit(h_deep,X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3a261",
   "metadata": {},
   "source": [
    "#### Prediction and Evaluation\n",
    "\n",
    "We need the predictions of label relevances for instances in the test set. We used sigmoid activation functions for each label, which represents the probability, according to our model, that each label should be assigned a 1 (indicating relevance); i.e.,  $\\sigma_j \\equiv p(y_j | \\bf{x})$. Let's walk away with these numbers, since it's easy to obtain the binary label predictions $\\hat y_j \\in \\{0,1\\}$ where $\\hat y_j = \\text{argmax}_{y_j \\in \\{0,1\\}} p(y_j \\mid \\bf{x})$, via a threshold of $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44dbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT infererence\n",
    "\n",
    "def predict_proba(h, X):\n",
    "    '''\n",
    "        Produce confidence for predicting 1 for each label for each instance in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        h : model\n",
    "            the PyTorch model/network\n",
    "        X : numpy array of shape (n, d)\n",
    "            test instances\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        P_Y : array of shape (n, m) where m the number of labels/outputs,\n",
    "              such that P_Y[i,j] is the relevance of the j-th label to the i-th instance.\n",
    "    '''\n",
    "\n",
    "    n_test = len(X)\n",
    "    P_Y = []\n",
    "\n",
    "    # Test the model on test data\n",
    "    with torch.no_grad():\n",
    "       for i in range(n_test):\n",
    "\n",
    "            x_t_variable = torch.FloatTensor(X[i]).view(1, -1)\n",
    "\n",
    "            output = h(x_t_variable)\n",
    "            p_y = torch.Tensor.numpy(output.detach())\n",
    "\n",
    "            P_Y.append(p_y[0])\n",
    "\n",
    "    return np.array(P_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate for exact-match (0/1 loss)\n",
    "P_pred = predict_proba(h_deep, X_test)\n",
    "Y_pred = (P_pred >= 0.5) * 1\n",
    "print(np.mean(np.sum(Y_pred == Y_test,axis=1) == m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d130b",
   "metadata": {},
   "source": [
    "### Conclusions and Reflection\n",
    "\n",
    "What does the output in the previous cell signify?\n",
    "\n",
    "How come that structure in particular? Wouldn't it work better to learn the structure from the data? Yes, this is intensive, but can be done; it can even be done with the same search methods we are using for inference (especially, e.g., Monte Carlo search). But others (that we will study in coming weeks) will be more suited. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442a7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
