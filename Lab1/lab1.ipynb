{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e99bb5",
   "metadata": {},
   "source": [
    "# INF581 - Lab 01\n",
    "\n",
    "### Main Objectives of the Lab \n",
    "\n",
    "Intelligent decision making involves several components. Today we will study, in the context of a toy (low-dimensional, synthetic) example: *perception* (observation), *knowledge* (representation), *reasoning* (inference), and *acting* (decision-making). We will _not_ look at (today) at learning and sequential decision making. Using probabalistic tools covered in the lecture (Bayesian networks, marginalization, ...), the objective is to design a rational/intelligent agent, i.e., an agent that maximizes expected reward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31b14d",
   "metadata": {},
   "source": [
    "\n",
    "### Instructions\n",
    "\n",
    "Work your way through the notebook, and provide code to complete the tasks. You can add as much code (and as many code blocks) as you want to solve the task, but make sure it is in a block containing an `## EXTRACT` tag, and don't change the names of existing functions or their parameters. Do not remove or add any of the `## EXTRACT` markers. Check Moodle for details on how to submit work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f4717",
   "metadata": {},
   "source": [
    "## Task 0: Name your work\n",
    "\n",
    "Replace the values in the following dictionary `info`. Your Email must match your class email address. Your Alias will be shown on the public leaderboard (to identify yourself). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0643a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT\n",
    "    \n",
    "info = {\n",
    "        'Email' : 'yannis.kedadry@polytechnique.edu',\n",
    "        'Alias' : 'yKedadry', # (change this in case you want to identify yourself on the leaderboard)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf216f",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "First, we're going to import `numpy` and some utility functions/classes that we will use throughout. You can come back later and add your own code if you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83e88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def tile2cell(y, n_col):\n",
    "    ''' utility function: convert tile number to matrix row, col'''\n",
    "    return int(y - 1) // n_col, int(y - 1) % n_col\n",
    "\n",
    "\n",
    "class PMF:\n",
    "\n",
    "    ''' Probability Mass Function representation and associated functions'''\n",
    "    \n",
    "    d = {} \n",
    "\n",
    "    def __init__(self,d = {}):\n",
    "        ''' use dictionary d to represent a pmf (and check that it is normalized) '''\n",
    "        Z = np.sum(np.array(list(d.values())))\n",
    "\n",
    "        if Z != 0 and Z != 1:\n",
    "            # normalize\n",
    "            d = {key: value / Z for key, value in d.items()}\n",
    "\n",
    "        self.d = d\n",
    "\n",
    "    def prob(self, x):\n",
    "        ''' evaluates p(x) where x a numpy array '''\n",
    "        x_str = ' '.join(map(str,x))\n",
    "        if x_str not in self.d.keys(): \n",
    "            return 0\n",
    "        return self.d[x_str] \n",
    "\n",
    "    def sample(self):\n",
    "        ''' samples x ~ p(x) where x a numpy array '''\n",
    "        x_str = np.random.choice(list(self.d.keys()), p=np.array(list(self.d.values())))\n",
    "        return np.fromstring(x_str.strip('[]').encode(), sep=' ', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2438a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e5cd6",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "Consider an intelligent robot tasked with catching rats in a storage room. It is night time, and the room is dark. You have to rely on auditory information only, but luckily the room is a mess with paper and other debris that means there are distinct sounds which are emitted by a rat as it touches different objects (namely, crinkling and rustling sounds). The room is rectangular, divided up into $n$ square tiles.  A rat has just entered the room (time $t=1$). The agent waits T seconds (until $t=T$), then makes a decision on if and where to pounce (in order to catch the rat).  \n",
    "\n",
    "Let's denote: $y_t \\in \\{1,\\ldots,n\\}$ the position (state) of the rat at time step $t$ (one of $n$ grid tiles); starting at some $y_1$ (entry tile). And $\\mathbf{x}_t \\in \\{0,1\\}^2$ is the 2-dimensional auditory observation at time $t$ (e.g., $\\mathbf{x}_t = [1,0]$ if there is a crinkle but no rustle, etc). The agent accumulates a sequence of $\\mathbf{x}_{1:T} = \\mathbf{x}_1,\\ldots,\\mathbf{x}_T$, which can be considered its input **observation**, with which to make the decision of taking **action** $a$ to pounce (denoting the tile upon which it pounces), or $a=0$ to not pounce. The agent obtains **reward** $r(s,a)$ (this function is already implemented in the environment), obviously catching the rat by pouncing to the correct tile ($s=a$) is better than missing it ($s\\neq a$).\n",
    "\n",
    "Your task is to model this problem, and provide the best action $a$ (according to current knowledge -- a given sequence $\\mathbf{x}_{1:T}$) and associated uncertainty.\n",
    "\n",
    "Be aware of the potential confusion here: $s = y_T$ represents the state of the environment at time $y_T$ and decision making (choosing action $a$) is based on observation $o = \\mathbf{x}_{1:T}$. Since the decision, being made at time $T$, does not affect the future observations, this is a Markov process + a decision rather than a Markov decision process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b051091",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You have full *knowledge* of the environment. Indeed, the Environment is fully specified for you, as a Markov process \n",
    "$$\n",
    "    y_{t+1} \\sim p(\\cdot | y_t)\n",
    "$$\n",
    "with observation process $\\mathbf{x}_t \\sim p( \\cdot | y_t)$. A `step` function is implemented to produce the observations.  \n",
    "\n",
    "Simply run the following code block then come back here to read the explanation for what you see. \n",
    "\n",
    "You can inspect the code to see that `P_Y_y` implements $p(\\cdot | y_t)$ such that the target moves by exactly $1$ square tile, either horizontally or vertically (i.e., taxicab-distance) per time step $t$, within the bounds of the of the room, starting at one of the entry points (uniformly at random) as specified by `P_Y`. Insofar as the observation function `P_X_y`: an audible 'crinkle' with probability $\\theta_1$ when over certain tiles (green, or orange) is emitted, and with probability $0$ over other tiles; furthermore, it will invoke a 'rustling' noise with probability $\\theta_2$ over certain tiles (red, or orange), and $0$ otherwise. On orange tiles, both noises are caused independently of each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "179b82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT ENVIRONMENT \n",
    "\n",
    "class Environment():\n",
    " \n",
    "    def __init__(self, G, theta = [0.9,0.8]):\n",
    "        ''' \n",
    "            Environment.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            \n",
    "            G : array_like(int, ndim=2) of shape (n_rows,n_columns) \n",
    "                Specifies a grid where G[j,k] = entry & sound1 & sound2\n",
    "        \n",
    "            theta : array_like(float, ndim=1) \n",
    "                Specifies the grid dynamics (acoustics) \n",
    "            \n",
    "        '''\n",
    "        # Grid\n",
    "        self.G = G\n",
    "        \n",
    "        # Grid shape\n",
    "        self.n_rows = G.shape[0]\n",
    "        self.n_cols = G.shape[1]\n",
    "        self.n_states = self.n_cols * self.n_rows\n",
    "        \n",
    "        # State space - tile number representation\n",
    "        self.states = np.arange(1,self.n_states+1)\n",
    "        \n",
    "        # Observation function\n",
    "        self.theta = theta\n",
    "\n",
    "    def getEntryPoints(self):\n",
    "        res = []\n",
    "        for i in range(len(self.G)):\n",
    "            for j in range(len(self.G[0])):\n",
    "                if self.G[i,j] >= 4:\n",
    "                    res.append(self.states[i,j])\n",
    "        return res\n",
    "   \n",
    "    def rwd(self, s, a): \n",
    "        '''\n",
    "            Reward function r(s, a) of taking action a given state s\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            s : int\n",
    "                true state (tile which containts the object)\n",
    "            a : int\n",
    "                estimated state\n",
    "                \n",
    "            Returns\n",
    "            -------\n",
    "            float\n",
    "                reward obtained from taking action a given state s\n",
    "        '''\n",
    "        return (s==a) * 10 + (s!=a) * -3\n",
    "   \n",
    "    def P_X_y(self,y):\n",
    "        ''' Observation distribution.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            s : int\n",
    "                current tile/state\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "                p where p[j] = p(Xj = 1 | y)\n",
    "        '''\n",
    "        # Convert to cell-coordinates representation\n",
    "        i,j = tile2cell(y, self.n_cols)\n",
    "        d = {}\n",
    "        if self.G[i,j] == 0 or self.G[i,j] > 3:\n",
    "            d = {\n",
    "                '0 0' : 1.0\n",
    "            }\n",
    "        elif self.G[i,j] == 1: # 0,1\n",
    "            d = {\n",
    "                '0 1' : self.theta[1],\n",
    "                '0 0' : 1 - self.theta[1],\n",
    "            }\n",
    "        elif self.G[i,j] == 2: # 1,0\n",
    "            d = {\n",
    "                '1 0' : self.theta[0],\n",
    "                '0 0' : 1-self.theta[0],\n",
    "            }\n",
    "        elif self.G[i,j] == 3:\n",
    "            d = {\n",
    "                '0 0' : (1 - self.theta[0]) * (1 - self.theta[1]),\n",
    "                '0 1' : self.theta[0] * (1-self.theta[0]),\n",
    "                '1 0' : (1-self.theta[0]) * (1-self.theta[1]),\n",
    "                '1 1' : self.theta[0] * self.theta[1],\n",
    "            }\n",
    "            \n",
    "        return PMF(d)\n",
    "\n",
    "    def P_Y(self):\n",
    "        ''' Distribution P(Y_1).\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            array_like (n_cols * n_rows) \n",
    "                where P[i,j] = P(Y_1 = y) where y the tile at row i, col j\n",
    "        '''\n",
    "        n_entries = np.sum(self.G >= 4)\n",
    "        return (self.G >= 4) * 1 / n_entries\n",
    "\n",
    "    def P_Y_y(self,_y):\n",
    "        ''' Distribution P(Y_t | Y_{t-1}).\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            _y : int\n",
    "                previous tile/state\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            array_like (n_cols * n_rows)\n",
    "                where P[i,j] = P(Y_t = y | Y_{t-1} = _y) where y the tile at row i, col j\n",
    "        '''\n",
    "        if _y is None:\n",
    "            return self.P_Y()\n",
    "\n",
    "        if _y not in self.states:\n",
    "            raise Exception(\"Sorry, %d is not one of the states\" % _y)\n",
    "\n",
    "        j,k = tile2cell(_y, self.n_cols)\n",
    "        \n",
    "        G = np.zeros_like(self.G)\n",
    "        if j > 0:\n",
    "            G[j-1,k] = 1\n",
    "        else:\n",
    "            G[j,k] = 1\n",
    "        if j < (self.n_rows-1):\n",
    "            G[j+1,k] = 1\n",
    "        else:\n",
    "            G[j,k] = 1\n",
    "        if k > 0:\n",
    "            G[j,k-1] = 1\n",
    "        else:\n",
    "            G[j,k] = 1    \n",
    "        if k < (self.n_cols-1):\n",
    "            G[j,k+1] = 1\n",
    "        else:\n",
    "            G[j,k] = 1\n",
    "\n",
    "        return G / np.sum(G)\n",
    "\n",
    "    def step(self, _y):\n",
    "        ''' Step to the next state, given current state _y.\n",
    "\n",
    "            The agent's actions do not affect the environment. \n",
    "            \n",
    "            \n",
    "            Paramaters\n",
    "            ----------\n",
    "            \n",
    "            _y : int\n",
    "                current state\n",
    "                \n",
    "            Returns   \n",
    "            -------\n",
    "            \n",
    "            y : int \n",
    "                next state\n",
    "            o : int\n",
    "                corresponding observation\n",
    "        '''  \n",
    "        # Generate a state y' ~ p( . | y)\n",
    "        w = self.P_Y_y(_y).flatten()\n",
    "        y = np.random.choice(self.n_states,p=w) + 1\n",
    "\n",
    "        # Generate an observation x' ~ p(. | y')\n",
    "        pmf = self.P_X_y(y) \n",
    "        x = pmf.sample()\n",
    "        \n",
    "        return y, x\n",
    "\n",
    "        \n",
    "    def gen_path(self, T=5):\n",
    "        ''' Generate a path with associated observations.\n",
    "\n",
    "\n",
    "            Paramaters\n",
    "            ----------\n",
    "            \n",
    "            T : int\n",
    "                how long is the path\n",
    "            \n",
    "            Returns   \n",
    "            -------\n",
    "            \n",
    "            x : (T,d)-shape array \n",
    "                sequence of observations\n",
    "            y : T-length array of states\n",
    "                sequence of tiles\n",
    "        '''\n",
    "\n",
    "        x = np.zeros((T,len(self.theta)),dtype=int)\n",
    "        y = np.zeros(T,dtype=int)\n",
    "\n",
    "        # (t-1)-th state\n",
    "        _y = None\n",
    "\n",
    "        for t in range(T):\n",
    "\n",
    "            # Generate next step\n",
    "            y[t], x[t] = self.step(_y)\n",
    "            \n",
    "            # And remember this state\n",
    "            _y = y[t]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def plot_scenario(self, y_seq=None, x_seq=None, dgrid=None, a_star=None, paths=[], title=None):\n",
    "        '''\n",
    "            Plot a visual representation of the environment.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            \n",
    "            y_seq : numpy array (dtype=int)\n",
    "                a path (e.g., [1,3,1,2])\n",
    "                \n",
    "            x_seq :\n",
    "                observations associated with the path\n",
    "                \n",
    "            dgrid : shape like self.G\n",
    "                contains values (e.g., probabilities) to show in each tile\n",
    "                \n",
    "            a_star : int\n",
    "                the optimal action\n",
    "                \n",
    "            title : str\n",
    "                a title for the plot\n",
    "                \n",
    "        '''\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=[8,4])\n",
    "\n",
    "        # Plot the tiles in the room\n",
    "\n",
    "        if dgrid is None:\n",
    "            color_map = ListedColormap([\"white\", \"green\", \"red\", \"orange\", \"yellow\"])\n",
    "            im = ax.imshow(self.G, cmap=color_map, interpolation='none',alpha=0.3)\n",
    "        else:\n",
    "            color_map = plt.cm.Reds\n",
    "            im = ax.imshow(dgrid, cmap=color_map)\n",
    "\n",
    "        # Plot the path, if there is one, e.g., [1,3,1,2,...]\n",
    "        # alongside the observations generated by that path, and the optimal action.\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "            \n",
    "        if y_seq is not None:\n",
    "            \n",
    "            # Draw the path\n",
    "            T = len(y_seq)\n",
    "            y_coords = np.array([tile2cell(y_t,env.n_cols)[0] for y_t in y_seq]) + np.random.randn(T)*0.1\n",
    "            x_coords = np.array([tile2cell(y_t,env.n_cols)[1] for y_t in y_seq]) + np.random.randn(T)*0.1\n",
    "            ax.plot(x_coords,y_coords,\"ko-\")\n",
    "            ax.plot(x_coords[-1],y_coords[-1],\"kx\",markersize=20)\n",
    "            \n",
    "            # Draw the action (i.e., target tile)\n",
    "            if a_star is not None:\n",
    "                y_coord = tile2cell(a_star,env.n_cols)[0]\n",
    "                x_coord = tile2cell(a_star,env.n_cols)[1]\n",
    "                ax.plot(x_coord,y_coord,\"m+\",markersize=15)    \n",
    "\n",
    "            # Draw the sounds (observations)\n",
    "            if x_seq is not None:\n",
    "                colors = [ im.cmap(im.norm(value)) for value in [1,2]]\n",
    "                indices = x_seq[:, 0] > 0\n",
    "                ax.scatter(np.array(x_coords)[indices], np.array(y_coords)[indices], marker='o', s=200, facecolors='none', edgecolors=colors[0])\n",
    "                indices = x_seq[:, 1] > 0\n",
    "                ax.scatter(np.array(x_coords)[indices], np.array(y_coords)[indices], marker='o', s=250, facecolors='none', edgecolors=colors[1])\n",
    "                           \n",
    "        \n",
    "        for path in paths:\n",
    "            # Draw the path\n",
    "            T = len(path)\n",
    "            y_coords = np.array([tile2cell(s,env.n_cols)[0] for s in path]) + np.random.randn(T)*0.1\n",
    "            x_coords = np.array([tile2cell(s,env.n_cols)[1] for s in path]) + np.random.randn(T)*0.1\n",
    "            ax.plot(x_coords,y_coords,\"mo:\")\n",
    "            ax.plot(x_coords[-1],y_coords[-1],\"mx\",markersize=10)\n",
    "        \n",
    "        \n",
    "        # Ticks and grid\n",
    "\n",
    "        ax.set_xticks(np.arange(0, self.n_cols, 1))\n",
    "        ax.set_xticks(np.arange(-0.5, self.n_cols, 1), minor=True)\n",
    "        ax.set_xticklabels(np.arange(0, self.n_cols, 1))\n",
    "\n",
    "        ax.set_yticks(np.arange(0, self.n_rows, 1))\n",
    "        ax.set_yticks(np.arange(-0.5, self.n_rows, 1), minor=True)\n",
    "        ax.set_yticklabels(np.arange(0, self.n_rows, 1))\n",
    "\n",
    "        ax.grid(which='minor', color='k')\n",
    "\n",
    "        n = 0\n",
    "        for i in range(self.n_rows):\n",
    "            for j in range(self.n_cols):\n",
    "              ax.text(j, i, self.states[n], va='center', ha='center')\n",
    "              n = n + 1\n",
    "\n",
    "        # Legend (for the map)\n",
    "\n",
    "        if dgrid is None:\n",
    "            labels = ['Crinkle', 'Rustle', 'Crinkle/rustle', 'Entry point']\n",
    "            colors = [ im.cmap(im.norm(value)) for value in range(1,len(labels)+1)]\n",
    "            patches = [ mpatches.Patch(color=colors[i], alpha=0.3, label=labels[i] ) for i in range(len(labels)) ]\n",
    "            plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "\n",
    "        # Return\n",
    "\n",
    "        plt.tight_layout()\n",
    "        return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff2102",
   "metadata": {},
   "source": [
    "### Instantiating the Environment\n",
    "\n",
    "Let's instantiate an environment, generate a path, and plot it. It is important to realise that although the agent can have full access to the environment, as well as observations, we do not have access to the true path $y_1,\\ldots,y_T$ and hence the challenge in estimating $y_T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b82c9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Design a map\n",
    "G = np.array([[1,3,0,2,4,1],\n",
    "              [2,1,0,3,0,3],\n",
    "              [4,0,3,0,2,0],\n",
    "              [3,1,2,3,0,4],\n",
    "              [2,0,0,0,1,1]]);\n",
    "\n",
    "# Init. the environment \n",
    "env = Environment(G)\n",
    "\n",
    "# Generate a path\n",
    "xxx, yyy = env.gen_path()\n",
    "fig, ax = env.plot_scenario(y_seq=yyy, x_seq=xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17644d",
   "metadata": {},
   "source": [
    "### Implementing the Agent \n",
    "\n",
    "Recall: The Agent is responsible for receiving observation $o = \\mathbf{x}_{1:T}$ and producing prediction $a$, i.e., it implements $a = \\pi(o)$, i.e., its policy or `action_selection` function as it is called here below. \n",
    "\n",
    "The following tasks should be implemented within the following `Agent` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a7ad571",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT AGENT\n",
    "\n",
    "class Agent():\n",
    "\n",
    "    def getPossiblePaths(self, xxx, env):\n",
    "        '''\n",
    "        return a list of possible paths (int, ndim=2) eg., [[1,2,3,4,5],[1,2,3,2,1],...]\n",
    "        '''\n",
    "        paths = []\n",
    "        # start from each possible starting points\n",
    "        for startPoint in env.getEntryPoints():\n",
    "            print(\"entry point: \", startPoint)\n",
    "            # for each cell in the grid, if the sound correspond to the observation, add it, otherwise discard\n",
    "            # repeat for all the remaining steps\n",
    "        \n",
    "        return paths\n",
    "\n",
    "\n",
    "    def P_YYY_xxx(self,xxx,env):\n",
    "        '''\n",
    "        Full conditional distribution of a path given sequence of observations. \n",
    "\n",
    "        $$\n",
    "            P( Y_1,...,Y_T | x_1,...,x_T )\n",
    "        $$\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        xxx : array_like(int,ndim=2)\n",
    "            T observations (of 2 bits each)\n",
    "\n",
    "        env : Environment \n",
    "            the environment that produced observation x\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict(str:float)\n",
    "            d such that d[str(yyy)] is the probability of observing path yyy\n",
    "            and if str(y) not in d, implies 0 probability\n",
    "            where yyy is array_like(int, ndim=1), e.g., [5, 4, 7, 13, 12]\n",
    "        '''\n",
    "\n",
    "        # create list of possible path (or use DFS, each entry point is a root)\n",
    "        possiblePaths = self.getPossiblePaths(xxx, env)\n",
    "        d = {}\n",
    "        return PMF(d)\n",
    "\n",
    "    def P_Y_xxx(self,xxx,env,t=-1): \n",
    "        '''        \n",
    "        The (conditional) marginal distribution on state t under observation xxx. \n",
    "\n",
    "        $$\n",
    "            P(Y_t | x_1,...,x_T ).\n",
    "        $$\n",
    "        \n",
    "        The probability (distribution) of the t-th state, given all the observed evidence.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        xxx : array_like(int,ndim=2)\n",
    "            T observations (of 2 bits each)\n",
    "\n",
    "        t : int\n",
    "            the given state, e.g., 3, or -1 for final state\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        P : array_like(float,ndim=2)\n",
    "            such that P[i,j] is the probability of being in state y_t at time t\n",
    "            where i,j = tile2cell(y_t)\n",
    "        '''\n",
    "\n",
    "        d_marg = {}\n",
    "\n",
    "        pmf = self.P_YYY_xxx(xxx,env) # Hint: this can save you some work\n",
    "\n",
    "        P = np.zeros_like(env.G,dtype=float)\n",
    "\n",
    "\n",
    "        return P \n",
    "\n",
    "    def Q_A(self,xxx,env):\n",
    "        '''\n",
    "        We want the reward (value) for any given action a.\n",
    "\n",
    "        $$\n",
    "            E[ r(S,a) | x_1,...,x_T ] \n",
    "        $$\n",
    "\n",
    "        Since you do not know the exact state, you need to marginalise out your uncertainty. \n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        xxx : array_like(int,ndim=2)\n",
    "            T observations (of 2 bits each)\n",
    "\n",
    "        env : Environment \n",
    "            the environment that implements env.rwd(s,a)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        Q : array_like(float,ndims=2)\n",
    "            such that Q[i,j] where tile2cell(a) is the value (expected reward) of action a.\n",
    "\n",
    "        '''\n",
    "\n",
    "        Q = np.zeros_like(env.G,dtype=float)\n",
    "\n",
    "        P = self.P_Y_xxx(xxx,env) # Hint\n",
    "\n",
    "\n",
    "        return Q\n",
    "\n",
    "    def action_selection(self,xxx,env):\n",
    "        '''\n",
    "        Decide on the best action to take, under observation xxx.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        xxx : array_like(int,ndim=2)\n",
    "            T observations (of 2 bits each)\n",
    "\n",
    "        env : Environment \n",
    "            the environment that implements env.rwd(s,a)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        int,float\n",
    "            the action a*, and its associated value Q(a*)\n",
    "\n",
    "        '''\n",
    "\n",
    "        Q = self.Q_A(xxx,env) # Hint\n",
    "\n",
    "        return a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fb1488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init. the agent \n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087a62f",
   "metadata": {},
   "source": [
    "## Task 1: Joint distribution (distribution over paths)\n",
    "\n",
    "What is the distribution over all paths the target could have taken for a given sequence of observations? We are looking for \n",
    "$$\n",
    "    P(Y_{1:T} | \\mathbf{x}_{1:T})\n",
    "$$\n",
    "\n",
    "**Task**: Edit the `Agent` code where indicated by `TODO`; specifically relating to function `P_YYY_xxx` (but you may add other functions if you need them). Run the following cell to have an idea of what is expected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be08a60f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Task 1. Get joint-conditional distribution\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pmf \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP_YYY_xxx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxxx\u001b[49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m pmf\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe could expect the path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with probabilty \u001b[39m\u001b[38;5;132;01m%8.6f\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (path, pmf\u001b[38;5;241m.\u001b[39mprob(path)))\n",
      "Cell \u001b[0;32mIn[55], line 45\u001b[0m, in \u001b[0;36mAgent.P_YYY_xxx\u001b[0;34m(self, xxx, env)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03mFull conditional distribution of a path given sequence of observations. \u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    where yyy is array_like(int, ndim=1), e.g., [5, 4, 7, 13, 12]\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# create list of possible path (or use DFS, each entry point is a root)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m possiblePaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetPossiblePaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxxx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m d \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PMF(d)\n",
      "Cell \u001b[0;32mIn[55], line 11\u001b[0m, in \u001b[0;36mAgent.getPossiblePaths\u001b[0;34m(self, xxx, env)\u001b[0m\n\u001b[1;32m      9\u001b[0m paths \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# start from each possible starting points\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m startPoint \u001b[38;5;129;01min\u001b[39;00m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetEntryPoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry point: \u001b[39m\u001b[38;5;124m\"\u001b[39m, startPoint)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# for each cell in the grid, if the sound correspond to the observation, add it, otherwise discard\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# repeat for all the remaining steps\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[53], line 38\u001b[0m, in \u001b[0;36mEnvironment.getEntryPoints\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG[i,j] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m             res\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# Task 1. Get joint-conditional distribution\n",
    "pmf = agent.P_YYY_xxx(xxx,env)\n",
    "path = pmf.sample()\n",
    "print(\"We could expect the path %s with probabilty %8.6f \" % (path, pmf.prob(path)))\n",
    "\n",
    "# Generate some possible paths\n",
    "paths = [pmf.sample() for i in range(10)]\n",
    "\n",
    "# ... and plot them\n",
    "fig, ax = env.plot_scenario(y_seq=yyy, x_seq=xxx, paths=paths, title=\"A sample of likely paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f9bee",
   "metadata": {},
   "source": [
    "## Task 2: Marginal distribution (over final states)\n",
    "\n",
    "What is the distribution over all final states the target could be at? We are looking for \n",
    "$$\n",
    "    P(Y_{T} | \\vec{x}_{1:T})\n",
    "$$\n",
    "\n",
    "**Task**: Edit the `Agent` code where indicated by `TODO`, in particular the `P_Y_xxx` function. Check the plot produced by the next cell to have an idea of what is expected. Recall: we do not have access to the path shown, only observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2. Get marginal distribution\n",
    "P = agent.P_Y_xxx(xxx,env)\n",
    "fig, ax = env.plot_scenario(y_seq=yyy, x_seq=xxx, dgrid=P, title=\"Marginal distribution of final states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daedb1e",
   "metadata": {},
   "source": [
    "## Task 3: Taking an Action\n",
    "\n",
    "You've now observed evidence $\\mathbf{x}_1,\\ldots,\\mathbf{x}_T$, and queried the model, according to your beliefs (environment dynamics). Time to make a decision. Which action to take?\n",
    "\n",
    "$$\n",
    "    a_* = \\text{argmax}_a E_{S \\sim P(Y_T | \\mathbf{x}_{1:T})}[ r(S, a) ]\n",
    "$$\n",
    "\n",
    "Note your uncertainty about the final state $S$. \n",
    "\n",
    "In this scenario the action will not affect future observations (because $y_T$ is the final observation), thus you are essentially making an estimate:\n",
    "$$\n",
    "    a = \\hat y_{T} = \\pi(\\mathbf{x}_{1:T})\n",
    "$$\n",
    "\n",
    "**Task 3a**: You need to evaluate the expectation. As this is essentially 'value', we call it `Q` inline with reinforcement learning terminology. You complete this task in the function `Q_A`. Hint: You already have $p(Y_T | \\vec{x}_{1,\\ldots,T})$\n",
    "\n",
    "**Task 3b**: Wrap the argmax around the outside (i.e., make the decision/take the action). This involves the function `action_selection`.\n",
    "\n",
    "Run the following code block to have a look at the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14232bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3. Obtain values\n",
    "Q = agent.Q_A(xxx,env)\n",
    "\n",
    "# Decide on an action\n",
    "a = agent.action_selection(xxx, env)\n",
    "\n",
    "# Compare to the ground truth\n",
    "r = env.rwd(yyy[-1],a)\n",
    "\n",
    "# Plot the result\n",
    "fig, ax = env.plot_scenario(y_seq=yyy, dgrid=Q, a_star=a, x_seq=xxx, title=\"Rewards for action %d; $r(%d,%d) = %d$\" % (a,yyy[-1],a,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237f94d",
   "metadata": {},
   "source": [
    "## Conclusion (So What?)\n",
    "\n",
    "Was it the right action? Did you expect to be? Recall what it implies (and what it doesn't imply) to be an optimal agent. \n",
    "\n",
    "This was just a toy example, but consider the fundamental concepts here (we will be using them again); and think about real-world examples where such an approach might be relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1668b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
